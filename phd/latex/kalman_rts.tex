\documentclass[fleqn]{article}
\usepackage[utf8]{inputenc}
\usepackage[margin=2cm]{geometry}

% maths
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}

% bibliography
\usepackage[round, sort&compress]{natbib}
\usepackage{har2nat}
\bibliographystyle{agsm}

% custom header/footer
\usepackage{fancyhdr}
\pagestyle{fancy}
\renewcommand{\headrulewidth}{0pt}
\fancyhf{}
\rfoot{\textsf{\thepage}}
\lfoot{\textsf{Suzie Brown}}

% pseudocode
\usepackage{algorithm}
\usepackage{algorithmicx}
\usepackage{algpseudocode}

% project-specific commands
\newcommand{\N}{\mathcal{N}}

\title{Exact smoothing for OU model}
\author{Suzie Brown}
\date{\today}

\begin{document}
\maketitle
\thispagestyle{fancy}

The discretised Ornstein-Uhlenbeck model is a hidden Markov model where the hidden states follow an AR(1) process. The model, which has two parameters $\Delta$ and $\sigma$, is specified below.
\begin{align*}
& X_0 \sim \N(0,1) \\
& X_{t+1} | X_t \sim \N((1-\Delta)X_t, \Delta) \\
& Y_t | X_t \sim \N(X_t, \sigma^2)
\end{align*}
Since this is a linear Gaussian model, the filtering distributions $p(x_t | y_{1:t})$ are available exactly and can be efficiently computed using the \emph{Kalman filter}. Furthermore, the smoothing distributions $p(x_{1:t} | y_{1:t})$ are also available exactly and can be computed using a forward pass of the Kalman filter (Algorithm \ref{alg:kalman}) followed by a backward pass of the Rauch-Tung-Striebel (RTS) smoother (Algorithm ??).

The filtering distribution at each time is Gaussian, so we need only compute the sequence of means and variances, and the same goes for the smoothing distributions. Our model is univariate, but both the Kalman filter and the RTS smoother readily generalise to multivariate processes.

\begin{algorithm}
\caption{Kalman filter for OU process}
\label{alg:kalman}
\begin{algorithmic}[1]
\Require $\Delta, \sigma, y_{1:T}$
\State $\hat{x}_{0|-1} \gets 0$
\State $\Sigma_{0|-1} \gets 1$
\For{$t = 0, \dots, T-1$}
	\State $\hat{x}_{t|t} \gets \hat{x}_{t|t-1} + \frac{\Sigma_{t|t-1}}{\Sigma_{t|t-1} + \sigma^2}(y_t - \hat{x}_{t|t-1})$
	\State $\Sigma_{t|t} \gets \Sigma_{t|t-1} - \frac{\Sigma_{t|t-1}^2}{\Sigma_{t|t-1} + \sigma^2}$
	\State $\hat{x}_{t+1|t} \gets (1-\Delta)\hat{x}_{t|t}$
	\State $\Sigma_{t+1|t} \gets (1-\Delta)^2 \Sigma_{t|t} + \Delta$
\EndFor
\State $\hat{x}_{T|T} \gets \hat{x}_{T|T-1} + \frac{\Sigma_{T|T-1}}{\Sigma_{T|T-1} + \sigma^2}(y_T - \hat{x}_{T|T-1})$
\State $\Sigma_{T|T} \gets \Sigma_{T|T-1} - \frac{\Sigma_{T|T-1}^2}{\Sigma_{T|T-1} + \sigma^2}$
\State\Return $(\hat{x}_{0|0}, \hat{x}_{1|1}, \dots, \hat{x}_{T|T}), (\Sigma_{0|0}, \Sigma_{1|1}, \dots, \Sigma_{T|T})$
\end{algorithmic}
\end{algorithm}

\bibliography{smc.bib}
\end{document}