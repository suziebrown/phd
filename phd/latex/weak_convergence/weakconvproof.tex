\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[margin=2cm]{geometry}

\usepackage{graphicx}
\usepackage{enumitem}

% custom header/footer
\usepackage{fancyhdr}
\pagestyle{fancy}
\renewcommand{\headrulewidth}{0pt}
\fancyhf{}
\rfoot{\textsf{\thepage}}
\lfoot{\textsf{Suzie Brown}}

%annotations
\usepackage{color}
\usepackage{xspace}
\newcommand{\seb}[1]{\xspace\textcolor{red}{#1}\xspace}

% bibliography
\usepackage[round, sort&compress]{natbib}
\usepackage{har2nat}
\bibliographystyle{agsm}

% maths
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{bbm}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newcommand{\Prob}{\mathbb{P}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\Et}{\mathbb{E}_t}
\newcommand{\V}{\operatorname{Var}}
\newcommand{\I}[1]{\mathbbm{1}_{\{#1\}}}
\newcommand{\1}[1]{\mathbbm{1}_{#1}}
\newcommand{\Mn}{\operatorname{Multinomial}}

\title{Weak convergence proof (in progress)}
\author{Suzie Brown}

\begin{document}
\maketitle
\thispagestyle{fancy}

\begin{theorem}\label{thm:weakconv}
Let $\nu_t^{(1:N)}$ denote the offspring numbers in an interacting particle system satisfying the standing assumption and such that, for any $N$ sufficiently large, for all finite $t$, $\Prob\{ \tau_N(t) = \infty \} =0$. Suppose that there exists a deterministic sequence $(b_N)_{N\geq1}$ such that ${\lim}_{N\to\infty} b_N =0$ and
\begin{equation}\label{eq:mainthmcond}
\frac{1}{(N)_3} \sum_{i = 1}^N \Et\{ (\nu_t^{(i)})_3 \}  \leq b_N \frac{1}{(N)_2} \sum_{i = 1}^N \Et\{ (\nu_t^{(i)})_2 \}
\end{equation}
for all $N$, uniformly in $t \geq 1$.
Then the rescaled genealogical process $(G_{\tau_N(t)}^{(n,N)})_{t\geq0}$ converges weakly %% in what topology?
to Kingman's $n$-coalescent as $N \to \infty$.
\end{theorem}

\begin{proof}
Define $p_t := \max_{\xi\in E} \{1 - p_{\xi\xi}(t)\} = 1 - p_{\Delta\Delta}(t)$, where $\Delta$ denotes the trivial partition of $\{1,\dots,n\}$ into singletons. For a proof that the maximum is attained at $\xi = \Delta$, see Lemma \ref{thm:maximum_pr}. 
Following \citet{mohle1999}, we now construct the two-dimensional Markov process $(Z_t, S_t)_{t \in \mathbb{N}}$ with transition probabilities
\begin{equation}
\Prob(Z_t = j , S_t = \eta \mid Z_{t-1} = i, S_{t-1} = \xi)
= \begin{cases}
1 - p_t &\quad \text{if } j=i \text{ and } \xi=\eta \\
p_{\xi\xi}(t) + p_t - 1  &\quad \text{if } j=i+1 \text{ and } \xi=\eta \\
p_{\xi\eta}(t) &\quad \text{if } j=i+1 \text{ and } \xi\neq\eta \\
0 &\quad \text{otherwise} .
\end{cases}
\end{equation}
The construction is such that the marginal $(S_t)$ has the same distribution as the genealogical process of interest, and $(Z_t)$ has jumps at all the times $(S_t)$ does plus some extra jumps. (The definition of $p_t$ ensures that the probability in the second case is non-negative, attaining the value zero when $\xi=\Delta$.)

Denote by $0=T_0^{(N)}<T_1^{(N)}<\dots$ the jump times of the rescaled process $(Z_{\tau_N(t)})_{t\geq0}$, and $\omega_i^{(N)} := T_i^{(N)} - T_{i-1}^{(N)}$ the corresponding holding times ($i\in\mathbb{N}$).

...
\end{proof}

\begin{lemma}\label{thm:maximum_pr}
$\max_{\xi\in E} (1 - p_{\xi\xi}(t)) = 1 - p_{\Delta\Delta}(t)$.
\end{lemma}
%%% This below proof is incorrect.
%\begin{proof}
%From the definition of $p_{\xi\eta}(t)$ \citep[Equation (1)]{koskela2018},
%\begin{equation}
%p_{\xi\xi}(t) = \frac{1}{(N)_{|\xi|}} \sum_{\substack{i_1,\dots,i_{|\xi|} \\ \text{all distinct}}} \nu_t^{(i_1)} \cdots \nu_t^{(i_{|\xi|})} .
%\end{equation}
%In the case $\xi = \Delta$, this simplifies to
%\begin{equation}
%p_{\Delta\Delta}(t) = \prod_{i=1}^N \nu_t^{(i)} 
%= \begin{cases}
%1 &\quad \text{if } \nu_t^{(1)}=\cdots=\nu_t^{(n)} \\
%0 &\quad \text{otherwise} .
%\end{cases}
%\end{equation}
%Whenever $p_{\Delta\Delta}(t) = 1$, $p_{\xi\xi}(t) = 1$ for all $\xi$ also. 
%Otherwise, $p_{\xi\xi}(t) \geq p_{\Delta\Delta}(t) = 0$ for all $\xi$, since $p_{\xi\xi}(t) \in [0,1]$.
%Hence $p_{\xi\xi}(t)$ attains its minimum at $\xi=\Delta$, and the result follows.
%\end{proof}
\begin{proof}
Consider any $\xi \in E$ consisting of $k$ blocks ($1\leq k\leq n-1$), and any $\xi^\prime\in E$ consisting of $k+1$ blocks. 
From the definition of $p_{\xi\eta}(t)$ \citep[Equation (1)]{koskela2018},
\begin{equation}
p_{\xi\xi}(t) = \frac{1}{(N)_k} \sum_{\substack{i_1,\dots,i_k \\ \text{all distinct}}} \nu_t^{(i_1)} \cdots \nu_t^{(i_k)} .
\end{equation}
Similarly,
\begin{align}
p_{\xi^\prime\xi^\prime}(t) &= \frac{1}{(N)_{k+1}} \sum_{\substack{i_1,\dots,i_k, i_{k+1} \\ \text{all distinct}}} \nu_t^{(i_1)} \cdots \nu_t^{(i_k)} \nu_t^{(i_{k+1})} \notag\\
&= \frac{1}{(N)_k(N-k)} \sum_{\substack{i_1,\dots,i_k \\ \text{all distinct}}} \left\{ \nu_t^{(i_1)} \cdots \nu_t^{(i_k)} \sum_{\substack{i_{k+1}=1 \\ \text{also distinct}}}^N \nu_t^{(i_{k+1})} \right\} .
\end{align}
Discarding the zero summands,
\begin{equation}
p_{\xi^\prime\xi^\prime}(t) = \frac{1}{(N)_k(N-k)} \sum_{\substack{i_1,\dots,i_k \\ \text{all distinct:} \\ \nu_t^{(i_1)},\dots,\nu_t^{(i_k)} > 0 }} \left\{ \nu_t^{(i_1)} \cdots \nu_t^{(i_k)} \sum_{\substack{i_{k+1}=1 \\ \text{also distinct}}}^N \nu_t^{(i_{k+1})} \right\} .
\end{equation}
The inner sum is
\begin{equation}
\sum_{\substack{i_{k+1}=1 \\ \text{also distinct}}}^N \nu_t^{(i_{k+1})} =
\left\{ \sum_{i=1}^N \nu_t^{(i)} -  \sum_{i\in\{i_1,\dots,i_k\} } \nu_t^{(i)} \right\}
\leq N - k
\end{equation}
since $\nu_t^{(i_1)},\dots,\nu_t^{(i_k)} $ are all at least 1.
Hence
\begin{equation}
p_{\xi^\prime\xi^\prime}(t)
\leq  \frac{N-k}{(N)_k(N-k)} \sum_{\substack{i_1,\dots,i_k \\ \text{all distinct:} \\ \nu_t^{(i_1)},\dots,\nu_t^{(i_k)} > 0 }} \nu_t^{(i_1)} \cdots \nu_t^{(i_k)} 
= p_{\xi\xi}(t) .
\end{equation}
Thus $p_{\xi\xi}(t)$ is decreasing in the number of blocks of $\xi$, and is therefore minimised by taking $\xi = \Delta$, which achieves the maximum $n$ blocks. This choice in turn maximises $1-p_{\xi\xi}(t)$, as required.
\end{proof}

\begin{lemma}
For any $0 < t < \infty$,
\begin{equation}
\lim_{N\to\infty} \E\left[ \prod_{r=1}^{\tau_N(t)} (1-p_r) \right] = e^{-\alpha_n t}
\end{equation}
where $\alpha_n := n(n-1)/2$.
\end{lemma}
\begin{proof}
%\textbf{\\Lower Bound}\\
%From \citet[Lemma 1 Case 1]{koskela2018}, taking $\xi=\Delta$, we have
%\begin{equation}
%1-p_t = p_{\Delta\Delta}(t) \geq 1 - \alpha_n (1+O(N^{-1})) \left[ \frac{(3n-1)(n-2)}{6N^2} + c_N(t) \right] .
%\end{equation}
%Hence, by a multinomial expansion,
%\begin{align*}
%\prod_{r=1}^{\tau_N(t)} (1-p_r)
%&\geq \prod_{r=1}^{\tau_N(t)} \left\{ 1 - \alpha_n (1+O(N^{-1}) \left[ \frac{(3n-1)(n-2)}{6N^2} + c_N(r) \right] \right\} \\
%&= 1 + \sum_{k=1}^\infty \sum_{\substack{r_1<\dots<r_k \\ =1}}^{\tau_N(t)}\prod_{j=1}^k 
%\left\{ - \alpha_n (1+O(N^{-1})) \left[ \frac{(3n-1)(n-2)}{6N^2} + c_N(r_j) \right] \right\} \\
%&= 1 + \sum_{k=1}^\infty \left\{- \alpha_n (1+O(N^{-1}))\right\}^k \sum_{\substack{r_1<\dots<r_k \\ =1}}^{\tau_N(t)}\prod_{j=1}^k 
%\left\{ \frac{(3n-1)(n-2)}{6N^2} + c_N(r_j) \right\} 
%\end{align*}
%where the empty sum is taken to be zero.
%Taking expectations,
%\begin{equation}\label{eq:9}
%\E \left[ \prod_{r=1}^{\tau_N(t)} (1-p_r) \right]
%\geq 1 + \sum_{k=1}^\infty \left\{- \alpha_n (1+O(N^{-1}))\right\}^k \E \left[ \sum_{\substack{r_1<\dots<r_k \\ =1}}^{\tau_N(t)}\prod_{j=1}^k 
%\left\{ \frac{(3n-1)(n-2)}{6N^2} + c_N(r_j) \right\} \right]
%\end{equation}
%(the infinite sum has only finitely many non-zero summands, since the inner sum is empty for $k>\tau_N(t)$, which justifies swapping the sum and expectation.)
%From \citet[Equation (8)]{koskela2018},
%\begin{align*}
%\sum_{\substack{r_1<\dots<r_k \\ =1}}^{\tau_N(t)}\prod_{j=1}^k 
%\left\{ \frac{(3n-1)(n-2)}{6N^2} + c_N(r_j) \right\}
%&\geq \sum_{\substack{r_1<\dots<r_k \\ =1}}^{\tau_N(t)}\prod_{j=1}^k c_N(r_j) \\
%&\geq \frac{1}{k!} \left( \sum_{s=1}^{\tau_N(t)} c_N(s) \right)^k 
%- \frac{1}{k!} \binom{k}{2} \left( \sum_{s=1}^{\tau_N(t)} c_N(s)^2 \right)
%\left( \sum_{s=1}^{\tau_N(t)} c_N(s) \right)^{k-2} \\
%&\geq \frac{1}{k!} t^k
% - \frac{1}{k!} \binom{k}{2} (t+1)^{k-2} \left( \sum_{s=1}^{\tau_N(t)} c_N(s)^2 \right) .
%\end{align*}
%Then 
%\begin{equation}\label{eq:10}
%\E\left[ \sum_{\substack{r_1<\dots<r_k \\ =1}}^{\tau_N(t)}\prod_{j=1}^k 
%\left\{ \frac{(3n-1)(n-2)}{6N^2} + c_N(r_j) \right\}  \right] 
%\geq \frac{1}{k!} t^k - \frac{1}{k!} \binom{k}{2} (t+1)^{k-2} \E\left[ \sum_{s=1}^{\tau_N(t)} c_N(s)^2 \right]
% \longrightarrow \frac{1}{k!} t^k
%\end{equation}
%as $N\to\infty$ using \citet[Equation (5)]{brown2020}, via lemmata 1 and 3 therein.
%Similarly, applying \citet[Equation (9)]{koskela2018},
%\begin{equation}
%\sum_{\substack{r_1<\dots<r_k \\ =1}}^{\tau_N(t)}\prod_{j=1}^k c_N(r_j)
%\leq \frac{1}{k!} \left( \sum_{r=1}^{\tau_N(t)} c_N(r) \right)^k
%\leq \frac{1}{k!} \{t+ c_N(\tau_N(t)) \}^k
%\end{equation}
%Note that since $c_N(s) \in [0,1]$ for all $s$, $\E[c_N(s)^k] \leq \E[c_N(s)]$ for all $k\geq 1$. Hence,
%as $N\to\infty$, using \citet[Equation (3)]{brown2020}.
%
%Combining these upper and lower limits, we conclude that
%\begin{equation}
%1 + \sum_{k=1}^\infty \left\{- \alpha_n (1+O(N^{-1}))\right\}^k \E \left[ \sum_{\substack{r_1<\dots<r_k \\ =1}}^{\tau_N(t)}\prod_{j=1}^k 
%\left\{ \frac{(3n-1)(n-2)}{6N^2} + c_N(r_j) \right\} \right]
%\longrightarrow 1+ \sum_{k=1}^\infty (-\alpha_n)^k \frac{1}{k!} t^k
%= e^{-\alpha_n t}
%\end{equation}
%as $N\to\infty$.
The strategy is to find upper and lower bounds on $\E\left[ \prod_{r=1}^{\tau_N(t)} (1-p_r) \right]$, both of which converge to $e^{-\alpha_n t}$.\\
\textbf{Lower Bound}\\ %(with weaker assumptions than above)
From \citet[Equation (14)]{brown2020}, taking $\xi=\Delta$, we have
\begin{equation}\label{eq:9a}
1-p_t = p_{\Delta\Delta}(t) \geq 1 - \alpha_n (1+O(N^{-1})) \left[c_N(t) + B_n D_N(t) \right]
\end{equation}
where $B_n >0$ and the $O(N^{-1})$ term does not depend on $t$.
In particular,
\begin{equation}
1-p_t = p_{\Delta\Delta}(t) \geq 1 - \frac{N^{n-2}}{(N-2)_{n-2}} \alpha_n c_N(t) - \frac{N^{n-3}}{(N-3)_{n-3}} B_n D_N(t) .
\end{equation}
Since $D_N(t) \leq c_N(t)$, a sufficient condition for the bound to be positive is
\begin{equation}
E_t := \left\{ c_N(t) < \frac{(N-3)_{n-3}}{N^{n-3}} \left( \alpha_n \left(1 + \frac{2}{N-2} \right) + B_n \right)^{-1} \right\} .
\end{equation}
%A sufficient condition for the RHS to be non-negative is $c_N(t) \leq [\alpha_n + B_n (1- 2/N)]^{-1}$. %% not true: check workings.
%% NB: $B_n$ here is equivalent to $B_n/\alpha_n$ in notation of \citet{koskela2018}.
Hence, by a multinomial expansion,
\begin{align}
\prod_{r=1}^{\tau_N(t)} (1-p_r)
&\geq \prod_{r=1}^{\tau_N(t)} \left\{ 1 - \alpha_n (1+O(N^{-1}))\left[ c_N(r) + B_n D_N(r) \right] \right\}
\times \prod_{r=1}^{\tau_N(t)} \1{E_r} \notag\\
&= \left( 1 + \sum_{k=1}^{\tau_N(t)} \sum_{\substack{r_1<\dots<r_k \\ =1}}^{\tau_N(t)}\prod_{j=1}^k 
\left\{ - \alpha_n (1+O(N^{-1})) \left[ c_N(r_j) + B_n D_N(r_j) \right] \right\} \right)
\times \prod_{r=1}^{\tau_N(t)} \1{E_r} \notag\\
&= \prod_{r=1}^{\tau_N(t)} \1{E_r} 
+ \sum_{k=1}^{\tau_N(t)} \left\{- \alpha_n (1+O(N^{-1}))\right\}^k 
\left(\prod_{r=1}^{\tau_N(t)} \1{E_r} \right)
\sum_{\substack{r_1<\dots<r_k \\ =1}}^{\tau_N(t)}\prod_{j=1}^k 
\left\{ c_N(r_j) + B_n D_N(r_j) \right\} .
\end{align}
%(The empty sum is defined to be zero and the empty product is defined to be one throughout.)
Taking expectations,
\begin{align}\label{eq:9}
\E \left[ \prod_{r=1}^{\tau_N(t)} (1-p_r) \right]
&\geq \E\left[ \prod_{r=1}^{\tau_N(t)} \1{E_r} \right] \notag\\
&\qquad + \E \left[ \sum_{k=1}^{\infty} \left\{- \alpha_n (1+O(N^{-1}))\right\}^k \I{k \leq \tau_N(t)} \1{\bigcap E_r} \sum_{\substack{r_1<\dots<r_k \\ =1}}^{\tau_N(t)}\prod_{j=1}^k 
\left\{ c_N(r_j) + B_n D_N(r_j) \right\} \right] \notag\\
&= \Prob \left[ \bigcap_{r=1}^{\tau_N(t)} E_r \right] \notag\\
&\qquad + \sum_{k=1}^{\infty} \left\{- \alpha_n (1+O(N^{-1}))\right\}^k
\E \left[ \sum_{\substack{r_1<\dots<r_k \\ =1}}^{\tau_N(t)}\prod_{j=1}^k 
\left\{ c_N(r_j) + B_n D_N(r_j) \right\} \middle| k\leq\tau_N(t), \bigcap_{r=1}^{\tau_N(t)} E_r \right] \notag\\
&\qquad \times \Prob \left[ k\leq \tau_N(t), \bigcap_{r=1}^{\tau_N(t)} E_r \right] .
\end{align}
%(the infinite sum has only finitely many non-zero summands, since the inner sum is empty for $k>\tau_N(t)$, which justifies swapping the sum and expectation.)
Swapping the expectation with the infinite sum is justified by the dominated convergence theorem, the calculations for which are almost identical to the invocation of Tannery's theorem in equations 
\eqref{eq:21a}--\eqref{eq:26a}.

We want to show that the conditional expectation on the right converges to $t^k/k!$, for reasons that will become clear. The strategy is to upper and lower bound this expectation by quantities that converge to $t^k/k!$. 

First the lower bound. 
Fix $k\leq \tau_N(t)$, so that the sum is non-empty.
%The conditioning on $\bigcap E_r$ doesn't affect these bounds, which are based on general properties of $c_N$, $D_N$ and $\tau_N$. %%% Is this true???
From \citet[Equation (8)]{koskela2018},
\begin{align}
\sum_{\substack{r_1<\dots<r_k \\ =1}}^{\tau_N(t)}\prod_{j=1}^k 
\left\{ c_N(r_j) + B_n D_N(r_j) \right\}
&\geq \sum_{\substack{r_1<\dots<r_k \\ =1}}^{\tau_N(t)}\prod_{j=1}^k c_N(r_j) \notag\\
&\geq \frac{1}{k!} \left( \sum_{s=1}^{\tau_N(t)} c_N(s) \right)^k 
- \frac{1}{k!} \binom{k}{2} \left( \sum_{s=1}^{\tau_N(t)} c_N(s)^2 \right)
\left( \sum_{s=1}^{\tau_N(t)} c_N(s) \right)^{k-2} \notag\\
&\geq \frac{1}{k!} t^k
 - \frac{1}{k!} \binom{k}{2} (t+1)^{k-2} \left( \sum_{s=1}^{\tau_N(t)} c_N(s)^2 \right) 
\end{align}
by the definition of $\tau_N$.
Then
\begin{align}\label{eq:10}
\E &\left[ \sum_{\substack{r_1<\dots<r_k \\ =1}}^{\tau_N(t)}\prod_{j=1}^k 
\left\{ c_N(r_j) + B_n D_N(r_j) \right\}  
\middle| k\leq\tau_N(t), \bigcap_{r=1}^{\tau_N(t)} E_r \right] \notag\\
&\qquad \geq \frac{1}{k!} t^k - \frac{1}{k!} \binom{k}{2} (t+1)^{k-2} \E\left[ \sum_{s=1}^{\tau_N(t)} c_N(s)^2 \middle| k\leq\tau_N(t), \bigcap_{r=1}^{\tau_N(t)} E_r \right] \notag\\
&\qquad = \frac{1}{k!} t^k - \frac{1}{k!} \binom{k}{2} (t+1)^{k-2} \E\left[ \sum_{s=1}^{\tau_N(t)} c_N(s)^2 \I{k\leq\tau_N(t)} \I{\bigcap_{r=1}^{\tau_N(t)} E_r} \right] \left(\Prob \left[k\leq\tau_N(t), \bigcap_{r=1}^{\tau_N(t)} E_r \right] \right)^{-1}  \notag\\
&\qquad \geq \frac{1}{k!} t^k - \frac{1}{k!} \binom{k}{2} (t+1)^{k-2} \E\left[ \sum_{s=1}^{\tau_N(t)} c_N(s)^2 \right]
\left(\Prob \left[k\leq\tau_N(t), \bigcap_{r=1}^{\tau_N(t)} E_r \right] \right)^{-1}
\longrightarrow \frac{1}{k!} t^k
\end{align}
as $N\to\infty$ using \citet[Equation (5)]{brown2020} and Lemma \ref{thm:indicators_prob1}. %, which is shown to hold via lemmata 1 and 3 therein.

Now for the upper bound. We start with a multinomial expansion and some manipulations of the sums:
\begin{align}
\sum_{\substack{r_1<\dots<r_k \\ =1}}^{\tau_N(t)}\prod_{j=1}^k 
\left\{ c_N(r_j) + B_n D_N(r_j) \right\}
&= \frac{1}{k!} \sum_{\substack{r_1\neq\dots\neq r_k \\\text{all distinct}}}^{\tau_N(t)}
\prod_{j=1}^k 
\left\{ c_N(r_j) + B_n D_N(r_j) \right\} \notag\\
&= \frac{1}{k!} \sum_{\substack{r_1\neq\dots\neq r_k \\\text{all distinct}}}^{\tau_N(t)} 
\sum_{\mathcal{I}\subseteq \{1,\dots ,k\}}  
( B_n )^{k-|\mathcal{I}|}
\left\{ \prod_{i\in\mathcal{I}} c_N(r_i) \right\} \left\{ \prod_{j\notin \mathcal{I}} D_N(r_j) \right\} \notag\\
&= \frac{1}{k!} 
\sum_{\mathcal{I}\subseteq \{1,\dots ,k\}}  
( B_n )^{k-|\mathcal{I}|}
\sum_{\substack{r_1\neq\dots\neq r_k \\\text{all distinct}}}^{\tau_N(t)}
\left\{ \prod_{i\in\mathcal{I}} c_N(r_i) \right\} \left\{ \prod_{j\notin \mathcal{I}} D_N(r_j) \right\} \notag\\
%&= \frac{1}{k!} \sum_{\substack{r_1\neq\dots\neq r_k \\\text{all distinct}}}^{\tau_N(t)} 
&= \frac{1}{k!}
\sum_{I=0}^k  \binom{k}{I}
( B_n )^{k-I}
\sum_{\substack{r_1\neq\dots\neq r_k \\\text{all distinct}}}^{\tau_N(t)} 
\left\{ \prod_{i=1}^{I} c_N(r_i) \right\} \left\{ \prod_{j=I+1}^k D_N(r_j) \right\} \notag\\
&= \frac{1}{k!} \sum_{\substack{r_1\neq\dots\neq r_k \\\text{all distinct}}}^{\tau_N(t)} 
\left\{ \prod_{i=1}^{k} c_N(r_i) \right\} \notag\\
&\qquad + \frac{1}{k!}
\sum_{I=0}^{k-1}  \binom{k}{I}
( B_n )^{k-I}
\sum_{\substack{r_1\neq\dots\neq r_k \\\text{all distinct}}}^{\tau_N(t)} 
\left\{ \prod_{i=1}^{I} c_N(r_i) \right\} \left\{ \prod_{j=I+1}^k D_N(r_j) \right\} .\label{eq:7}
%\left\{ \prod_{i=1}^{k} c_N(r_i) \right\} \notag\\
%&\qquad + \frac{1}{k!}
%\sum_{\mathcal{I}\subset \{1,\dots ,k\}}  
%( B_n )^{k-|\mathcal{I}|}
%\sum_{\substack{r_1\neq\dots\neq r_k \\\text{all distinct}}}^{\tau_N(t)}
%\left\{ \prod_{i\in\mathcal{I}} c_N(r_i) \right\} \left\{ \prod_{j\notin \mathcal{I}} D_N(r_j) \right\} 
\end{align}
Then, using that $D_N(s) \leq c_N(s)$ for all $s$ \citep[p.9]{koskela2018}, along with the definition of $\tau_N$,
\begin{align}
\frac{1}{k!} \sum_{\substack{r_1\neq\dots\neq r_k \\\text{all distinct}}}^{\tau_N(t)} 
\left\{ \prod_{i=1}^{k} c_N(r_i) \right\} 
& + \frac{1}{k!}
\sum_{I=0}^{k-1}  \binom{k}{I}
( B_n )^{k-I}
\sum_{\substack{r_1\neq\dots\neq r_k \\\text{all distinct}}}^{\tau_N(t)} 
\left\{ \prod_{i=1}^{I} c_N(r_i) \right\} \left\{ \prod_{j=I+1}^k D_N(r_j) \right\}\notag\\
%\frac{1}{k!} \sum_{\substack{r_1\neq\dots\neq r_k \\\text{all distinct}}}^{\tau_N(t)} 
%\left\{ \prod_{i=1}^{k} c_N(r_i) \right\} 
%& + \frac{1}{k!}
%\sum_{\mathcal{I}\subset \{1,\dots ,k\}}  
%( B_n )^{k-|\mathcal{I}|}
%\sum_{\substack{r_1\neq\dots\neq r_k \\\text{all distinct}}}^{\tau_N(t)}
%\left\{ \prod_{i\in\mathcal{I}} c_N(r_i) \right\} \left\{ \prod_{j\notin \mathcal{I}} D_N(r_j) \right\} \notag\\
&\leq  \frac{1}{k!} \left( \sum_{r=1}^{\tau_N(t)} c_N(r) \right)^k
+ \frac{1}{k!}
\sum_{I=0}^{k-1}  \binom{k}{I}
( B_n )^{k-I}
\sum_{\substack{r_1\neq\dots\neq r_k \\\text{all distinct}}}^{\tau_N(t)} 
\left\{ \prod_{i=1}^{k-1} c_N(r_i) \right\} D_N(r_k) \notag\\
&\leq  \frac{1}{k!} \left\{ t + c_N(\tau_N(t)) \right\}^k
+ \frac{1}{k!}
\sum_{I=0}^{k-1}  \binom{k}{I}
( B_n )^{k-I}
\left\{ \sum_{\substack{r_1\neq\dots\neq r_{k-1} \\\text{all distinct}}}^{\tau_N(t)} 
\prod_{i=1}^{k-1} c_N(r_i) \right\} 
\left( \sum_{r_k =1}^{\tau_N(t)} D_N(r_k) \right) \notag\\
&\leq  \frac{1}{k!} \left\{ t + c_N(\tau_N(t)) \right\}^k
+ \frac{1}{k!}
\sum_{I=0}^{k-1}  \binom{k}{I}
( B_n )^{k-I}
\left( \sum_{r=1}^{\tau_N(t)} c_N(r) \right)^{k-1}
\left( \sum_{r=1}^{\tau_N(t)} D_N(r) \right) \notag\\
&\leq  \frac{1}{k!} \left\{ t + c_N(\tau_N(t)) \right\}^k
+ \frac{1}{k!}
\sum_{I=0}^{k-1}  \binom{k}{I}
( B_n )^{k-I}
(t+1)^{k-1}
\left( \sum_{r=1}^{\tau_N(t)} D_N(r) \right) . \label{eq:8}
\end{align}
%%% old version of the mega-align
%&\leq \frac{1}{k!}
%\sum_{I=0}^k  \binom{k}{I}
%\left( B_n \right)^{k-I}
%\left\{\sum_{\substack{r_1\neq\dots\neq r_I \\\text{all distinct}}}^{\tau_N(t)}  \prod_{i=1}^{I} c_N(r_i) \right\} 
%\left\{ \sum_{\substack{r_{I+1}\neq\dots\neq r_k \\\text{all distinct}}}^{\tau_N(t)}  \prod_{j=I+1}^k D_N(r_j) \right\} \\
%&\leq \frac{1}{k!}
%\sum_{I=0}^k  \binom{k}{I}
%\left( B_n \right)^{k-I}
%\left( \sum_{r=1}^{\tau_N(t)} c_N(r) \right)^I
%\left( \sum_{s=1}^{\tau_N(t)} D_N(s) \right)^{k-I} \\
%&\leq \frac{1}{k!}
%\sum_{I=0}^k  \binom{k}{I}
%\left( B_n \right)^{k-I}
%\left( t+ c_N(\tau_N(t)) \right)^I
%\left( \sum_{s=1}^{\tau_N(t)} D_N(s) \right)^{k-I} \\
%&= \frac{1}{k!} \{ t+c_N(\tau_N(t)) \}^k
%+ \frac{1}{k!}
%\sum_{I=0}^{k-1}  \binom{k}{I}
%\left( B_n \right)^{k-I}
%\left( t+ c_N(\tau_N(t)) \right)^I
%\left( \sum_{s=1}^{\tau_N(t)} D_N(s) \right)^{k-I} \\
%&\leq \frac{1}{k!} \{ t+c_N(\tau_N(t)) \}^k
%+ \frac{1}{k!}
%\sum_{I=0}^{k-1}  \binom{k}{I}
%\left( B_n \right)^{k-I}
%(t+1)^I
%\left( \sum_{s=1}^{\tau_N(t)} D_N(s) \right)^{k-I} 
Taking expectations, 
\begin{align}
\E &\left[ \sum_{\substack{r_1<\dots<r_k \\ =1}}^{\tau_N(t)}\prod_{j=1}^k 
\left\{ c_N(r_j) + B_n D_N(r_j) \right\} 
\middle| k\leq\tau_N(t), \bigcap_{r=1}^{\tau_N(t)} E_r \right] \notag\\
&\leq \frac{1}{k!} \E \left[ \left\{ t + c_N(\tau_N(t)) \right\}^k
\middle| k\leq\tau_N(t), \bigcap_{r=1}^{\tau_N(t)} E_r \right] \notag\\
&\qquad+ \frac{1}{k!}
\sum_{I=0}^{k-1}  \binom{k}{I}
( B_n )^{k-I}
(t+1)^{k-1}
\E\left[ \sum_{r=1}^{\tau_N(t)} D_N(r) \middle| k\leq\tau_N(t), \bigcap_{r=1}^{\tau_N(t)} E_r \right] \notag\\
&= \frac{1}{k!} \E \left[ \left\{ t + c_N(\tau_N(t)) \right\}^k
\I{k\leq\tau_N(t)} \I{\bigcap E_r} \right] 
\left(\Prob \left[k\leq\tau_N(t), \bigcap_{r=1}^{\tau_N(t)} E_r \right] \right)^{-1} \notag\\
&\qquad+ \frac{1}{k!}
\sum_{I=0}^{k-1}  \binom{k}{I}
( B_n )^{k-I}
(t+1)^{k-1}
\E\left[ \sum_{r=1}^{\tau_N(t)} D_N(r) \I{k\leq\tau_N(t)} \I{\bigcap E_r} \right]
\left(\Prob \left[k\leq\tau_N(t), \bigcap_{r=1}^{\tau_N(t)} E_r \right] \right)^{-1} \notag\\
& \leq \left(
\frac{1}{k!} \E \left[ \left\{ t + c_N(\tau_N(t)) \right\}^k \right] 
+ \frac{1}{k!}
\sum_{I=0}^{k-1}  \binom{k}{I}
( B_n )^{k-I}
(t+1)^{k-1}
\E\left[ \sum_{r=1}^{\tau_N(t)} D_N(r) \right]
\right)
\left(\Prob \left[k\leq\tau_N(t), \bigcap_{r=1}^{\tau_N(t)} E_r \right] \right)^{-1} \notag\\
&\longrightarrow \frac{1}{k!} t^k . \label{eq:19a}
\end{align}
%%% even decreasing expectation of D_N ?
The limit follows from Lemma \ref{thm:indicators_prob1} and \citet[Equations (3),(4)]{brown2020} along with the fact that, since $c_N(s) \in [0,1]$ for all $s$, $\E[c_N(s)^k] \leq \E[c_N(s)]$ for all $k\geq 1$, and the expansion
\begin{equation}\label{eq:11}
\E\left[ \{t+ c_N(\tau_N(t)) \}^k \right]
%\middle| k\leq\tau_N(t ), \bigcap_{r=1}^{\tau_N(t)} E_r \right]
%= \sum_{i=0}^k \binom{k}{i} t^i \,
%\E\left[ c_N(\tau_N(t))^{k-i} \middle| k\leq\tau_N(t), \bigcap_{r=1}^{\tau_N(t)} E_r \right]
%\leq 
=\sum_{i=0}^k \binom{k}{i} t^i \,
\E\left[ c_N(\tau_N(t))^{k-i} \right]
%= \left\{ t^k + k t^{k-1} \E[c_N(\tau_N(t))] + \dots \right\}
\longrightarrow t^k 
\end{equation}
which holds for any fixed $k$.

Combining the upper and lower limits, we conclude that, for any fixed $k\leq \tau_N(t)$,
\begin{equation}\label{eq:19}
\lim_{N\to\infty} \E \left[ \sum_{\substack{r_1<\dots<r_k \\ =1}}^{\tau_N(t)}\prod_{j=1}^k 
\left\{ c_N(r_j) + B_n D_N(r_j) \right\} 
\middle| k\leq\tau_N(t), \bigcap_{r=1}^{\tau_N(t)} E_r \right]
= \frac{1}{k!} t^k .
\end{equation}
Now, starting with \eqref{eq:9}, we have
\begin{align}\label{eq:21a}
\lim_{N\to\infty} &\E \left[ \prod_{r=1}^{\tau_N(t)} (1-p_r) \right]
\geq \lim_{N\to\infty} \Prob \left[ \bigcap_{r=1}^{\tau_N(t)} E_r \right] \notag\\
&+ \lim_{N\to\infty} \sum_{k=1}^\infty \left\{ -\alpha_n (1+ O(N^{-1})) \right\}^k 
\E \left[ \sum_{\substack{r_1<\dots<r_k \\ =1}}^{\tau_N(t)}\prod_{j=1}^k 
\left\{ c_N(r_j) + B_n D_N(r_j) \right\} \middle| k\leq\tau_N(t), \bigcap_{r=1}^{\tau_N(t)} E_r \right]
\Prob \left[ k \leq \tau_N(t) , \bigcap_{r=1}^{\tau_N(t)} E_r \right]
\end{align}
Since $\tau_N(t) \to \infty$, some care must be taken when exchanging the limit with the sum. We will use Tannery's theorem (a special case of dominated convergence) to show that this is okay.
Let 
\begin{equation}
a_k(N) := \{ -\alpha_n (1+ O(N^{-1})) \}^k 
\E \left[ \sum_{\substack{r_1<\dots<r_k \\ =1}}^{\tau_N(t)}\prod_{j=1}^k 
\left\{ c_N(r_j) + B_n D_N(r_j) \right\} \middle| k\leq\tau_N(t), \bigcap_{r=1}^{\tau_N(t)} E_r \right]
\Prob \left[ k \leq \tau_N(t) , \bigcap_{r=1}^{\tau_N(t)} E_r \right] .
\end{equation}
We know from \eqref{eq:19} and Lemma \ref{thm:indicators_prob1} that
\begin{equation}
\lim_{N\to\infty} a_k(N) = (-\alpha_n)^k \frac{1}{k!}t^k =: b_k.
\end{equation}
Furthermore, using \eqref{eq:19a},
\begin{align}
|a_k(N)| 
&\leq \{ \alpha_n (1+ O(N^{-1})) \}^k 
\left( \frac{1}{k!} (t+1)^k + \frac{1}{k!} \sum_{I=0}^{k-1} \binom{k}{I} (B_n)^{k-I} (t+1)^{k-1} \E \left[ \sum_{r=1}^{\tau_N(t)} c_N(r) \right] \right) \times 1 \notag\\
&\leq \{ \alpha_n (1+ O(N^{-1})) \}^k 
\left( \frac{1}{k!} (t+1)^k + \frac{1}{k!} \sum_{I=0}^{k-1} \binom{k}{I} (B_n)^{k-I} (t+1)^k \right) \notag\\
&= \{ \alpha_n (1+ O(N^{-1})) \}^k 
\frac{1}{k!} (t+1)^k \left( 1+\sum_{I=0}^{k-1} \binom{k}{I} (B_n)^{k-I} \right) \notag\\
&= \{ \alpha_n (1+ O(N^{-1})) \}^k \frac{1}{k!} (t+1)^k (1 + B_n)^k 
=: M_k .
\end{align}
Now
\begin{equation}
\sum_{k=0}^\infty M_k = \exp \left\{ \alpha_n (1+O(N^{-1})) (t+1) (1+B_n) \right\} < \infty
\end{equation}
so we can apply Tannery's theorem:
\begin{equation}\label{eq:26a}
\lim_{N\to\infty} \sum_{k=1}^\infty a_k(N)
= \sum_{k=1}^\infty b_k
= e^{-\alpha_n t} -1
\end{equation}
and finally, applying Lemma \ref{thm:indicators_prob1},
\begin{equation}
\lim_{N\to\infty} \E \left[ \prod_{r=1}^{\tau_N(t)} (1-p_r) \right]
\geq 1 + e^{-\alpha_n t} -1 = e^{-\alpha_n t} .
\end{equation}
%\begin{equation}
%1 + \sum_{k=1}^\infty \left\{- \alpha_n (1+O(N^{-1}))\right\}^k \E \left[ \sum_{\substack{r_1<\dots<r_k \\ =1}}^{\tau_N(t)}\prod_{j=1}^k 
%\left\{ c_N(r_j) + B_n D_N(r_j) \right\} \right]
%\longrightarrow 1+ \sum_{k=1}^\infty (-\alpha_n)^k \frac{1}{k!} t^k
%= e^{-\alpha_n t}
%\end{equation}
%%%
%\\---\\
%\begin{align}\label{eq:20}
%\lim_{N\to\infty} &\E \left[ \prod_{r=1}^{\tau_N(t)} \1{E_r} 
%+ \sum_{k=1}^{\tau_N(t)} \left\{- \alpha_n (1+O(N^{-1}))\right\}^k 
%\left(\prod_{r=1}^{\tau_N(t)} \1{E_r} \right)
%\sum_{\substack{r_1<\dots<r_k \\ =1}}^{\tau_N(t)}\prod_{j=1}^k 
%\left\{ c_N(r_j) + B_n D_N(r_j) \right\} \right] \notag\\
%&= \lim_{N\to\infty} \Prob \left[ \bigcap_{r=1}^{\tau_N(t)} E_r \right] \notag\\
%&\qquad + \lim_{N\to\infty} \sum_{k=1}^\infty \left\{- \alpha_n (1+O(N^{-1}))\right\}^k
%\E \left[ \I{k\leq\tau_N(t)} \left(\prod_{r=1}^{\tau_N(t)} \1{E_r} \right) \sum_{\substack{r_1<\dots<r_k \\ =1}}^{\tau_N(t)}\prod_{j=1}^k 
%\left\{ c_N(r_j) + B_n D_N(r_j) \right\} \right] \notag\\
%&= \lim_{N\to\infty} \Prob \left[ \bigcap_{r=1}^{\tau_N(t)} E_r \right] \notag\\
%&\qquad + \sum_{k=1}^\infty (-\alpha_n)^k 
%\lim_{N\to\infty} \E \left[ \sum_{\substack{r_1<\dots<r_k \\ =1}}^{\tau_N(t)}\prod_{j=1}^k 
%\left\{ c_N(r_j) + B_n D_N(r_j) \right\} \middle| k\leq\tau_N(t), \bigcap_{r=1}^{\tau_N(t)} E_r \right]
%\times \lim_{N\to\infty}\Prob \left[ k\leq \tau_N(t), \bigcap_{r=1}^{\tau_N(t)} E_r \right] \notag\\
%&= 1+ \sum_{k=1}^\infty (-\alpha_n)^k \frac{t^k}{k!} \times 1 = e^{-\alpha_n t} 
%\end{align}
%as $N\to\infty$, where the last line follows from \eqref{eq:19} and Lemma \ref{thm:indicators_prob1}.


\textbf{\\Upper Bound}\\
From \citet[Lemma 1 Case 1]{koskela2018}, taking $\xi=\Delta$, we have
\begin{equation}
1-p_t = p_{\Delta\Delta}(t) \leq 1 - \alpha_n (1+O(N^{-1})) \left[ c_N(t) - B_n^\prime D_N(t) \right] 
\end{equation}
where the $O(N^{-1})$ term does not depend on $t$.
%% NB: $B_n^\prime = \binom{n-1}{2}$.
A multinomial expansion as in the lower bound yields
\begin{equation}
\prod_{r=1}^{\tau_N(t)} (1-p_r)
\leq 1 + \sum_{k=1}^{\tau_N(t)} \left\{- \alpha_n (1+O(N^{-1}))\right\}^k \sum_{\substack{r_1<\dots<r_k \\ =1}}^{\tau_N(t)}\prod_{j=1}^k 
\left\{ c_N(r_j) - B_n^\prime D_N(r_j) \right\} .
\end{equation}
%Similarly to \eqref{eq:10}, an upper bound for the inner sum is
%\begin{equation}
%\sum_{\substack{r_1<\dots<r_k \\ =1}}^{\tau_N(t)}\prod_{j=1}^k 
%\left\{ c_N(r_j) - B_n^\prime D_N(r_j) \right\}
%\leq \sum_{\substack{r_1<\dots<r_k \\ =1}}^{\tau_N(t)}\prod_{j=1}^k c_N(r_j)
%\leq \frac{1}{k!} \left( \sum_{r=1}^{\tau_N(t)} c_N(r) \right)^k
%\leq \frac{1}{k!} \{ t + c_N(\tau_N(t)) \}^k 
%\end{equation}
%with $\E[ \{ t + c_N(\tau_N(t)) \}^k] \longrightarrow t^k$ as shown in \eqref{eq:11}.
Analogously to \eqref{eq:7}, for fixed $k\leq\tau_N(t)$ we can write
\begin{align}
\sum_{\substack{r_1<\dots<r_k \\ =1}}^{\tau_N(t)}\prod_{j=1}^k 
\left\{ c_N(r_j) - B_n^\prime D_N(r_j) \right\}
&= \frac{1}{k!} \sum_{\substack{r_1\neq\dots\neq r_k \\ \text{all distinct}}}^{\tau_N(t)}
\left\{ \prod_{i=1}^k c_N(r_i) \right\} \label{eq:18}\\
&\qquad + \frac{1}{k!} \sum_{I=0}^{k-1} \binom{k}{I} \left( -B_n^\prime \right)^{k-I}
\sum_{\substack{r_1\neq\dots\neq r_k \\ \text{all distinct}}}
\left\{ \prod_{i=1}^I c_N(r_i) \right\}
\left\{ \prod_{j=I+1}^k D_N(r_j) \right\} .\notag
\end{align}
We start by dealing with the second term:
\begin{align}
\frac{1}{k!} \sum_{I=0}^{k-1} \binom{k}{I} \left( -B_n^\prime \right)^{k-I}
&\sum_{\substack{r_1\neq\dots\neq r_k \\ \text{all distinct}}}
\left\{ \prod_{i=1}^I c_N(r_i) \right\}
\left\{ \prod_{j=I+1}^k D_N(r_j) \right\} \notag\\
&= \frac{1}{k!} \sum_{\substack{I=0:\\k-I \text{ even}}}^{k-1} \binom{k}{I} (B_n^\prime)^{k-I}
\sum_{\substack{r_1\neq\dots\neq r_k \\ \text{all distinct}}}
\left\{ \prod_{i=1}^I c_N(r_i) \right\}
\left\{ \prod_{j=I+1}^k D_N(r_j) \right\} \notag\\
&\qquad - \frac{1}{k!} \sum_{\substack{I=0:\\k-I \text{ odd}}}^{k-1} \binom{k}{I} (B_n^\prime)^{k-I}
\sum_{\substack{r_1\neq\dots\neq r_k \\ \text{all distinct}}}
\left\{ \prod_{i=1}^I c_N(r_i) \right\}
\left\{ \prod_{j=I+1}^k D_N(r_j) \right\} .
\end{align}
This is lower bounded by
\begin{equation}
0 
- \frac{1}{k!} \sum_{\substack{I=0 \\ k-I \text{ odd}}}^{k-1}  \binom{k}{I} (B_n^\prime)^{k-I}
(t+1)^{k-1}
\left( \sum_{s=1}^{\tau_N(t)} D_N(s) \right)
\end{equation}
using that $c_N(r), D_N(r) \geq 0$ for all $r$ to bound the even terms below, and arguments from \eqref{eq:8} to bound the odd terms above.
The same arguments lead to the upper bound
\begin{equation}
\frac{1}{k!} \sum_{\substack{I=0 \\ k-I \text{ even}}}^{k-1}  \binom{k}{I} (B_n^\prime)^{k-I}
(t+1)^{k-1}
\left( \sum_{s=1}^{\tau_N(t)} D_N(s) \right)
-0 .
\end{equation}
By \citet[Equation (4)]{brown2020}, both bounds have vanishing expectation as $N\to\infty$.
We are left with the first term in \eqref{eq:18}, which is upper bounded by
\begin{equation}
\frac{1}{k!} \sum_{\substack{r_1\neq\dots\neq r_k \\ \text{all distinct}}}^{\tau_N(t)}
\left\{ \prod_{i=1}^k c_N(r_i) \right\}
\leq \frac{1}{k!}\left( \sum_{s=1}^{\tau_N(t)} c_N(s) \right)^k
\leq \frac{1}{k!} \{t + c_N(\tau_N(t)) \}^k
\end{equation}
the expectation of which (conditional on $k\leq\tau_N(t)$; otherwise the sum is empty and has expectation zero) converges to $t^k/k!$ as in \eqref{eq:11}.
We use \citet[Equation (8)]{koskela2018} to construct a lower bound:
\begin{align}
\frac{1}{k!} \sum_{\substack{r_1\neq\dots\neq r_k \\ \text{all distinct}}}^{\tau_N(t)}
\left\{ \prod_{i=1}^k c_N(r_i) \right\} 
&\geq \frac{1}{k!} \left( \sum_{s=1}^{\tau_N(t)} c_N(s) \right)^k
- \frac{1}{k!} \binom{k}{2}  \left( \sum_{s=1}^{\tau_N(t)} c_N(s)^2 \right)  \left( \sum_{s=1}^{\tau_N(t)} c_N(s) \right)^{k-2} \notag\\
&\geq \frac{1}{k!} t^k - \frac{1}{k!} \binom{k}{2} (t+1)^{k-2}  \left( \sum_{s=1}^{\tau_N(t)} c_N(s)^2 \right)
\end{align}
The expectation of this bound (conditional on $k\leq\tau_N(t)$) also converges to $t^k/k!$, using \citet[Equation (5)]{brown2020}.
%To bound the first term we again call on \citet[Equation (8)]{koskela2018}:
%\begin{align*}
%\frac{1}{k!} \sum_{\substack{r_1\neq\dots\neq r_k \\ \text{all distinct}}}^{\tau_N(t)}
%\left\{ \prod_{i=1}^k c_N(r_i) \right\} 
%&\geq \frac{1}{k!} \left( \sum_{s=1}^{\tau_N(t)} c_N(s) \right)^k
%- \frac{1}{k!} \binom{k}{2}  \left( \sum_{s=1}^{\tau_N(t)} c_N(s)^2 \right)  \left( \sum_{s=1}^{\tau_N(t)} c_N(s) \right)^{k-2} \\
%&\geq \frac{1}{k!} t^k - \frac{1}{k!} \binom{k}{2} (t+1)^{k-2}  \left( \sum_{s=1}^{\tau_N(t)} c_N(s)^2 \right)
%\end{align*}
%and as in \eqref{eq:10} we obtain 
%\begin{equation}
%\lim_{N\to\infty} \E \left[ \frac{1}{k!} t^k - \frac{1}{k!} \binom{k}{2} (t+1)^{k-2}  \left( \sum_{s=1}^{\tau_N(t)} c_N(s)^2 \right) \right] = \frac{1}{k!} t^k .
%\end{equation}
%It remains to show that the expectation of the second term converges to zero.
%\begin{align*}
% \frac{1}{k!} \sum_{I=0}^{k-1} \binom{k}{I} \left( -\binom{n-1}{2} \right)^{k-I}
%&\sum_{\substack{r_1\neq\dots\neq r_k \\ \text{all distinct}}}
%\left\{ \prod_{i=1}^I c_N(r_i) \right\}
%\left\{ \prod_{j=I+1}^k D_N(r_j) \right\} \\
%&= \frac{1}{k!} \sum_{\substack{I=0 \\ (k-I) \text{even}}}^{k-1}  \binom{k}{I} \binom{n-1}{2}^{k-I}
%\sum_{\substack{r_1\neq\dots\neq r_k \\ \text{all distinct}}}
%\left\{ \prod_{i=1}^I c_N(r_i) \right\}
%\left\{ \prod_{j=I+1}^k D_N(r_j) \right\} \\
%&\qquad - \frac{1}{k!} \sum_{\substack{I=0 \\ (k-I) \text{odd}}}^{k-1}  \binom{k}{I} \binom{n-1}{2}^{k-I}
%\sum_{\substack{r_1\neq\dots\neq r_k \\ \text{all distinct}}}
%\left\{ \prod_{i=1}^I c_N(r_i) \right\}
%\left\{ \prod_{j=I+1}^k D_N(r_j) \right\} \\
%&\geq 0 
%- \frac{1}{k!} \sum_{\substack{I=0 \\ (k-I) \text{odd}}}^{k-1}  \binom{k}{I} \binom{n-1}{2}^{k-I}
%(t+1)^{k-1}
%\left( \sum_{s=1}^{\tau_N(t)} D_N(s) \right) \\
%\end{align*}
%using that $c_N(r), D_N(r) \geq 0$ for all $r$ to bound the even terms below, and arguments from \eqref{eq:8} to bound the odd terms above.
%Taking expectations, we obtain
%\begin{align*}
%\lim_{N\to\infty} &\E \left[ \frac{1}{k!} \sum_{I=0}^{k-1} \binom{k}{I} \left( -\binom{n-1}{2} \right)^{k-I}
%\sum_{\substack{r_1\neq\dots\neq r_k \\ \text{all distinct}}}
%\left\{ \prod_{i=1}^I c_N(r_i) \right\}
%\left\{ \prod_{j=I+1}^k D_N(r_j) \right\} \right] \\
%&\qquad\qquad \geq - \frac{1}{k!} \sum_{\substack{I=0 \\ (k-I) \text{odd}}}^{k-1}  \binom{k}{I} \binom{n-1}{2}^{k-I}
%(t+1)^{k-1}
%\lim_{N\to\infty} \E \left[ \sum_{s=1}^{\tau_N(t)} D_N(s) \right]
%= 0 .
%\end{align*}
We can now conclude that
\begin{equation}
\lim_{N\to\infty} \E \left[ \sum_{\substack{r_1<\dots<r_k \\ =1}}^{\tau_N(t)}\prod_{j=1}^k 
\left\{ c_N(r_j) - B_n^\prime D_N(r_j) \right\} \middle| k\leq \tau_N(t) \right]
= \frac{1}{k!} t^k
\end{equation}
and thus, applying dominated convergence and Tannery's theorem as in the lower bound, along with Lemma \ref{thm:indicators_prob1},
\begin{align}
\lim_{N\to\infty} &\E\left[ \prod_{r=1}^{\tau_N(t)} (1-p_r) \right] \notag\\
&\leq \lim_{N\to\infty} \E\left[
1 + \sum_{k=1}^{\tau_N(t)} \left\{- \alpha_n (1+O(N^{-1}))\right\}^k \sum_{\substack{r_1<\dots<r_k \\ =1}}^{\tau_N(t)}\prod_{j=1}^k 
\left\{ c_N(r_j) - B_n^\prime D_N(r_j) \right\} \right] \notag\\
&= 1 + \sum_{k=1}^\infty \lim_{N\to\infty} \{ -\alpha_n(1+O(N^{-1})) \}^k
\lim_{N\to\infty} \E \left[ \sum_{\substack{r_1<\dots<r_k \\ =1}}^{\tau_N(t)}\prod_{j=1}^k 
\left\{ c_N(r_j) - B_n^\prime D_N(r_j) \right\} \middle| k\leq \tau_N(t) \right]
\lim_{N\to\infty} \Prob\left[ k\leq \tau_N(t) \right] \notag\\
&= 1+ \sum_{k=1}^\infty (-\alpha_n)^k \frac{1}{k!} t^k
= e^{-\alpha_n t} .
\end{align}

We now have upper and lower bounds on $\lim_{N\to\infty} \E\left[ \prod_{r=1}^{\tau_N(t)} (1-p_r) \right]$, both of which are equal to $e^{-\alpha_n t}$, and the result follows.
\end{proof}


%\begin{lemma}
%For any $n \leq N \in \mathbb{N}$, for all $t \in \mathbb{N}$, define 
%\begin{equation}
%E_t := \left\{ c_N(t) < \frac{(N-3)_{n-3}}{N^{n-3}} \left( \alpha_n \left(1 + \frac{2}{N-2} \right) + B_n \right)^{-1} \right\} 
%\end{equation}
%where $\alpha_n$ and $B_n$ are positive constants as in \eqref{eq:9a}.
%Then, for all $t>0$,
%\begin{equation}
%\lim_{N\to\infty} \Prob \left[  \bigcap_{r=1}^{\tau_N(t)} E_r \right] = 1 .
%\end{equation}
%\end{lemma}
%\begin{proof}
%\begin{align}
%\Prob \left[  \bigcap_{r=1}^{\tau_N(t)} E_r \right]
%&= 1 - \Prob \left[  \bigcup_{r=1}^{\tau_N(t)} E_r^c \right]
%= 1 - \E \left[ \1{\bigcup E_r^c} \right]
%\geq 1 - \E \left[ \sum_{r=1}^{\tau_N(t)} \1{E_r^c} \right] \notag\\
%&= 1 - \E \left[ \sum_{r=1}^{\tau_N(t)}  \E [ \1{E_r^c} \mid \mathcal{F}_{r-1} ] \right]
%= 1 - \E \left[ \sum_{r=1}^{\tau_N(t)} \Prob [E_r^c \mid \mathcal{F}_{r-1} ] \right] 
%\end{align}
%where the inequality holds by considering the two possible values of $\1{\bigcup E_r^c}$, and the second line follows from Lemma \ref{thm:kjjslemma2} with $f(r) = \1{E_r^c}$.
%Using the generalised Markov inequality,
%\begin{align}
%\Prob [E_r^c \mid \mathcal{F}_{r-1} ] &= \Prob \left[ c_N(r) \geq \frac{(N-3)_{n-3}}{N^{n-3}} \left( \alpha_n \left(1 + \frac{2}{N-2} \right) + B_n \right)^{-1} \middle| \mathcal{F}_{r-1} \right] \notag\\
%&\leq \E[c_N(r)^2 \mid \mathcal{F}_{r-1} ] \frac{N^{2(n-3)}}{(N-3)_{n-3}^2} \left( \alpha_n \left(1 + \frac{2}{N-2} \right) + B_n \right)^2 .
%\end{align}
%Now, using Lemma \ref{thm:kjjslemma2} again, this time with $f(r) = c_N(r)^2$,
%\begin{align}
%\Prob \left[  \bigcap_{r=1}^{\tau_N(t)} E_r \right]
%&\geq 1 - \E \left[  \sum_{r=1}^{\tau_N(t)} \E[c_N(r)^2 \mid \mathcal{F}_{r-1} ] \frac{N^{2(n-3)}}{(N-3)_{n-3}^2} \left( \alpha_n \left(1 + \frac{2}{N-2} \right) + B_n \right)^2 \right] \notag\\
%&= 1 - \frac{N^{2(n-3)}}{(N-3)_{n-3}^2} \left( \alpha_n \left(1 + \frac{2}{N-2} \right) + B_n \right)^2 
%\E \left[ \sum_{r=1}^{\tau_N(t)} \E[c_N(r)^2 \mid \mathcal{F}_{r-1} ] \right] \notag\\
%&= 1 - \frac{N^{2(n-3)}}{(N-3)_{n-3}^2} \left( \alpha_n \left(1 + \frac{2}{N-2} \right) + B_n \right)^2 
%\E \left[ \sum_{r=1}^{\tau_N(t)} c_N(r)^2 \right] \notag\\
%&\overset{N\to\infty}{\longrightarrow} 1 - (\alpha_n + B_n)^2 \times 0 = 1 .
%\end{align}
%\end{proof}

\begin{lemma}\label{thm:indicators_prob1}
For all $k \in \mathbb{N}$, for all $t>0$,
\begin{equation}\label{eq:37}
\lim_{N\to\infty} \Prob \left[k \leq \tau_N(t), \bigcap_{r=1}^{\tau_N(t)} E_r \right] = 1 
\end{equation}
and consequently
\begin{equation}\label{eq:37a}
\lim_{N\to\infty} \Prob \left[ \bigcap_{r=1}^{\tau_N(t)} E_r \right] = 1 
\qquad \text{and} \qquad
\lim_{N\to\infty} \Prob \left[ k \leq \tau_N(t) \right] = 1 .
\end{equation}
\end{lemma}

\begin{proof}
We first construct a constant $C_1$ such that 
\begin{equation}\label{eq:38}
\Prob \left[  \bigcap_{r=1}^{\tau_N(t)} \{ c_N(r) < C_1 \} \right]
\leq \Prob \left[k \leq \tau_N(t), \bigcap_{r=1}^{\tau_N(t)} E_r \right]
\end{equation}
and
\begin{equation}\label{eq:39}
\lim_{N\to\infty} \Prob \left[  \bigcap_{r=1}^{\tau_N(t)} \{ c_N(r) < C_1 \} \right] =1 .
\end{equation}
Any $C_1 \leq \frac{(N-3)_{n-3}}{N^{n-3}} \left( \alpha_n \left(1 + \frac{2}{N-2} \right) + B_n \right)^{-1}$ will suffice to ensure that $\{c_N(r) < C_1\} \subseteq E_r$ for all $r$.
Furthermore, we can write 
\begin{equation}
\{ \tau_N(t) \geq k \} 
= \left\{ \min \left\{ s \geq 1 : \sum_{r=1}^{s} c_N(r) \geq t \right\} \geq k \right\}
= \left\{ \sum_{r=1}^{k-1} c_N(r) < t \right\}
\supseteq \bigcap_{r=1}^{k-1} \left \{ c_N(r) < \frac{t}{k} \right\}.
\end{equation}
A suitable choice to satisfy \eqref{eq:38} would thus be
\begin{equation}
C_1 = \min \left\{ \frac{(N-3)_{n-3}}{N^{n-3}} \left( \alpha_n \left(1 + \frac{2}{N-2} \right) + B_n \right)^{-1} ,\, \frac{t}{k} \right\} .
\end{equation}
Now we show that this choice of $C_1$ satisfies \eqref{eq:39}.
\begin{align}
\Prob \left[  \bigcap_{r=1}^{\tau_N(t)} \{c_N(r) < C_1\} \right]
&= 1 - \Prob \left[  \bigcup_{r=1}^{\tau_N(t)} \{c_N(r) \geq C_1\} \right]
= 1 - \E \left[ \1{\bigcup \{c_N(r) \geq C_1\} } \right]
\geq 1 - \E \left[ \sum_{r=1}^{\tau_N(t)} \1{\{c_N(r) \geq C_1\}} \right] \notag\\
&= 1 - \E \left[ \sum_{r=1}^{\tau_N(t)}  \E [ \1{\{c_N(r) \geq C_1\}} \mid \mathcal{F}_{r-1} ] \right]
= 1 - \E \left[ \sum_{r=1}^{\tau_N(t)} \Prob [\{c_N(r) \geq C_1\} \mid \mathcal{F}_{r-1} ] \right] 
\end{align}
where the inequality holds by considering the two possible values of $\1{\bigcup \{c_N(r) \geq C_1\}}$, and the second line follows from Lemma \ref{thm:kjjslemma2} with $f(r) = \1{\{c_N(r) \geq C_1\}}$.
Using the generalised Markov inequality,
\begin{align}
\Prob [\{c_N(r) \geq C_1\} \mid \mathcal{F}_{r-1} ] 
\leq C_1^{-2} \, \E[c_N(r)^2 \mid \mathcal{F}_{r-1} ] .
\end{align}
Now, using Lemma \ref{thm:kjjslemma2} again, this time with $f(r) = c_N(r)^2$,
\begin{align}
\Prob \left[  \bigcap_{r=1}^{\tau_N(t)} \{c_N(r) < C_1\} \right]
&\geq 1 - \E \left[  \sum_{r=1}^{\tau_N(t)} C_1^{-2} \, \E[c_N(r)^2 \mid \mathcal{F}_{r-1} ] \right] \notag\\
&= 1 - C_1^{-2} \,
\E \left[ \sum_{r=1}^{\tau_N(t)} \E[c_N(r)^2 \mid \mathcal{F}_{r-1} ] \right] \notag\\
&= 1 - C_1^{-2} \,
\E \left[ \sum_{r=1}^{\tau_N(t)} c_N(r)^2 \right] \notag\\
&\overset{N\to\infty}{\longrightarrow} 1 - \min\{(\alpha_n + B_n)^2 , k^2/t^2 \} \times 0 = 1 .
\end{align}
Clearly $\Prob \left[k \leq \tau_N(t), \bigcap_{r=1}^{\tau_N(t)} E_r \right] \leq \Prob \left[\bigcap_{r=1}^{\tau_N(t)} E_r \right]$ and $\Prob \left[k \leq \tau_N(t), \bigcap_{r=1}^{\tau_N(t)} E_r \right] \leq \Prob \left[ k \leq \tau_N(t) \right]$, so \eqref{eq:37a} follows as an immediate corollary.
\end{proof}


The following Lemma is taken from \citet[Lemma 2]{koskela2018}, where the function is set to $f(t) = c_N(t)$, but the authors remark that the result holds for other choices of function.
\begin{lemma}\label{thm:kjjslemma2}
Let $(\mathcal{F}_t)$ be the backwards-in-time filtration generated by the offspring counts $\nu_t^{(1:N)}$ at each generation $t$,
and let $f(t)$ be any deterministic function of $\nu_t^{(1:N)}$.
Then
\begin{equation}
\E \left[ \sum_{r=1}^{\tau_N(t)} f(r) \right] 
= \E \left[ \sum_{r=1}^{\tau_N(t)} \E [ f(r) \mid \mathcal{F}_{r-1} ] \right] .
\end{equation}
\end{lemma}

\begin{proof}
Define 
\begin{equation}
M_s := \sum_{r=1}^s \left\{ f(r) - \E [ f(r) \mid \mathcal{F}_{r-1} ] \right\} .
\end{equation}
It is easy to see that $(M_s)$ is a martingale with respect to $(\mathcal{F}_s)$, and $M_0 = 0$. 
Now fix $K>0$ and note that $\tau_N(t) \wedge K$ is a bounded $\mathcal{F}_t$-stopping time.
Hence we can apply the optional stopping theorem:
\begin{align}
\E [M_{\tau_N(t) \wedge K} ]
= \E \left[ \sum_{r=1}^{\tau_N(t) \wedge K} \left\{ f(r) - \E [ f(r) \mid \mathcal{F}_{r-1} ] \right\} \right]
= \E \left[ \sum_{r=1}^{\tau_N(t) \wedge K} f(r) \right]
- \E \left[ \sum_{r=1}^{\tau_N(t) \wedge K} \E [ f(r) \mid \mathcal{F}_{r-1} ] \right]
=0 .
\end{align}
Taking $K\to\infty$ and applying the monotone convergence theorem concludes the proof.
\end{proof}

\bibliography{../smc.bib}
\end{document}